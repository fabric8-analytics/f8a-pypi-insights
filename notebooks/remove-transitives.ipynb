{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Transitives\n",
    "\n",
    "In this notebook, we explore how to remove transitives from the training of python HPF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pip._internal.req.req_file import parse_requirements\n",
    "from pip._internal.download import PipSession\n",
    "import requests\n",
    "import requests_cache\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pip._vendor.distlib.util import normalize_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_cache.install_cache(expire_after=timedelta(hours=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start by seeing how to get transitives for a package from pypa api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = PipSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url='https://pypi.org/pypi/flask/json', headers={\"Accept\": \"application/json\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "requires_dist = c.get('info', {}).get('requires_dist', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Werkzeug (>=0.15)',\n",
       " 'Jinja2 (>=2.10.1)',\n",
       " 'itsdangerous (>=0.24)',\n",
       " 'click (>=5.1)',\n",
       " \"pytest ; extra == 'dev'\",\n",
       " \"coverage ; extra == 'dev'\",\n",
       " \"tox ; extra == 'dev'\",\n",
       " \"sphinx ; extra == 'dev'\",\n",
       " \"pallets-sphinx-themes ; extra == 'dev'\",\n",
       " \"sphinxcontrib-log-cabinet ; extra == 'dev'\",\n",
       " \"sphinx-issues ; extra == 'dev'\",\n",
       " \"sphinx ; extra == 'docs'\",\n",
       " \"pallets-sphinx-themes ; extra == 'docs'\",\n",
       " \"sphinxcontrib-log-cabinet ; extra == 'docs'\",\n",
       " \"sphinx-issues ; extra == 'docs'\",\n",
       " \"python-dotenv ; extra == 'dotenv'\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## These are the transitives for flask. Remember, this is not the complete graph of dependencies that flask requires.\n",
    "## It's just first level transitives\n",
    "requires_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now parse the transitives to get the names and normalize those names as well. We don't filter out extra dependencies, because we also want to remove those when somebody is using that extra field while installing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "werkzeug\n",
      "jinja2\n",
      "itsdangerous\n",
      "click\n",
      "pytest\n",
      "coverage\n",
      "tox\n",
      "sphinx\n",
      "pallets-sphinx-themes\n",
      "sphinxcontrib-log-cabinet\n",
      "sphinx-issues\n",
      "sphinx\n",
      "pallets-sphinx-themes\n",
      "sphinxcontrib-log-cabinet\n",
      "sphinx-issues\n",
      "python-dotenv\n"
     ]
    }
   ],
   "source": [
    "for d in requires_dist:\n",
    "    print(normalize_name(d.split()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above logic seems to be working fine. Let's start looking at BQ data and filter out the transitives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_json = [{\n",
    "    \"ecosystem\": \"pypi\",\n",
    "    \"package_list\": []\n",
    "}]\n",
    "\n",
    "manifest_json_without_transitives = [{\n",
    "    \"ecosystem\": \"pypi\",\n",
    "    \"package_list\": []\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_tuple_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_transitives(req_names, trans_names):\n",
    "    req_names = set(req_names) - trans_names\n",
    "    return list(req_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's the get to the actual work now\n",
    "\n",
    "Here we do the following:\n",
    "1. We open the data gathered from BQ and start processing the requirements.txt\n",
    "2. For each requirement in requirement.txt we get the first level transitives using the above logic.\n",
    "3. Now, we will have transitives for every dependency mentioned in the requirements.txt\n",
    "4. We remove all the transitives from requirements.txt and save the direct requirements.\n",
    "\n",
    "To give an example as to why this works by figuring out just the first level transitives is: \n",
    "\n",
    "Let's assume the following package list: {a, b, c, d}. We now take the following cases:\n",
    "\n",
    "1. a->b, b->c, c->d. So when you calculate the total transitive graph, b c and d will be eliminated\n",
    "2. a->b, b->d. Here a and c will be directs\n",
    "\n",
    "Similarly, we can think of other examples. One case that I can think of is: a->b, b->c and then c->a. I don't think if that is even possible in python, but I think it is because you can basically install a and then b and then c given the version constraints are satisfied. But in the above case, we will end up removing all the three dependencies. IMO we aren't losing on much because such cases rarely exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"python-bigquery-data.json\", \"r\") as f, open('error-log-pip-trans.txt', 'a') as log:\n",
    "    content = json.load(f)\n",
    "    for x in content:\n",
    "        if x.get('content'):\n",
    "            with open(\"temp-requirements.txt\", \"w\") as w:\n",
    "                w.write(x.get('content'))\n",
    "            req_names = []\n",
    "            trans_names = set()\n",
    "            try:\n",
    "                for p in parse_requirements(\"temp-requirements.txt\", session=session):\n",
    "                    if p.name:\n",
    "                        name = normalize_name(p.name)\n",
    "                        r = requests.get(url='https://pypi.org/pypi/{}/json'.format(name), headers={\"Accept\": \"application/json\"})\n",
    "                        if r.status_code == 200:\n",
    "                            print(\"Package: {} done\".format(name))\n",
    "                            req_names.append(name)\n",
    "                            response = r.json()\n",
    "                            requires_dist = response.get('info', {}).get('requires_dist', [])\n",
    "                            requires_dist = [] if not requires_dist else requires_dist\n",
    "                            requires_dist = [normalize_name(d.split()[0]) for d in requires_dist]\n",
    "                            for r in requires_dist:\n",
    "                                trans_names.add(r)\n",
    "            except Exception as e:\n",
    "                log.write(str(e))\n",
    "            manifest_json[0].get(\"package_list\").append(req_names)\n",
    "            req_names_direct = remove_transitives(req_names, trans_names)\n",
    "            manifest_json_without_transitives[0].get(\"package_list\").append(req_names_direct)\n",
    "            length_tuple_list.append((len(req_names), len(req_names_direct)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We save the files below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('manifest-list-with-trans.json', 'w') as f:\n",
    "    json.dump(manifest_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('manifest-list-without-trans.json', 'w') as f:\n",
    "    json.dump(manifest_json_without_transitives, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161562"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(length_tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('length-tuple.pkl', 'wb') as f:\n",
    "    pickle.dump(length_tuple_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
